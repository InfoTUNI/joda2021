{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"credit_train.csv\")\n",
    "\n",
    "def siivoaData(data, slice=1.0):\n",
    "\n",
    "    # Mikä on muuttuja josta olemme kiinnostuneita?\n",
    "    # Haluamme tietysti ymmärtää muuttujaa lainan tilanne \"Loan staus\"\n",
    "    # Dikotominne muuttuja kuvaa sitä maksetaanko laina takaisin vai ei.\n",
    "\n",
    "    #Haluammeko poistaa jotain muuttujia?\n",
    "    poistettavatMuuttujat = ['Loan ID','Customer ID']\n",
    "    data = data.drop(poistettavatMuuttujat, axis=1)\n",
    "\n",
    "    #Annetaan keskiarvot puutuville tietopisteille\n",
    "    sarakkeet =['Current Loan Amount','Credit Score','Annual Income','Years of Credit History',\n",
    "            'Months since last delinquent','Number of Open Accounts','Number of Credit Problems',\n",
    "           'Current Credit Balance','Maximum Open Credit','Bankruptcies','Tax Liens']\n",
    "    muuttujanTäyttäjä = Imputer()\n",
    "    data[sarakkeet] = muuttujanTäyttäjä.fit_transform(data[sarakkeet])\n",
    "    data[sarakkeet] = data[sarakkeet].astype(int)\n",
    "\n",
    "    #Poistetaan vielä NaN rivit\n",
    "    data=data.dropna()\n",
    "\n",
    "    #Note:  Discarding half of the data for testing purposes!\n",
    "    mid_point = int(len(data)*slice)\n",
    "    data = data.loc[:mid_point]\n",
    "\n",
    "\n",
    "    #Valitaan muuttuja josta olemme kiinnostuneita ja koodataan se\n",
    "    y = data['Loan Status']\n",
    "    new_y = []\n",
    "    for i in y:\n",
    "        if i == 'Fully Paid':\n",
    "            new_y.append(1)\n",
    "        else:\n",
    "            new_y.append(0)\n",
    "    data = data.drop('Loan Status', axis=1)\n",
    "\n",
    "    # Koodataan kategoriset muuttujat\n",
    "    data = pd.get_dummies(data)\n",
    "    #print(data.head())\n",
    "\n",
    "    # Normalisoidaan data\n",
    "    # Palautamme myös dataMean ja dataDev arvot jos haluamme syöttää koneelle uusia havaintoja\n",
    "    dataMean = np.mean(data, axis=0)\n",
    "    dataDev = np.std(data, axis=0)\n",
    "    norm_x= (data - dataMean) / dataDev\n",
    "\n",
    "    x = data.values #muutetaan numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    normMinMax = pd.DataFrame(x_scaled)\n",
    "\n",
    "    return norm_x, normMinMax, data, new_y, dataMean, dataDev\n",
    "\n",
    "xNorm, xMinMax, xNoNorm, y, xMean, xDev = siivoaData(df, slice=0.25)\n",
    "\n",
    "cases = []\n",
    "\n",
    "for x in [xNorm, xMinMax, xNoNorm]:\n",
    "    case = {}\n",
    "    case['x_train'], case['x_test'], case['y_train'], case['y_test'] = train_test_split(x, y, test_size= 0.25, random_state=33)\n",
    "    cases.append(case)\n",
    "\n",
    "classifiers = [SGDClassifier(), LogisticRegression(), SVC()]\n",
    "\n",
    "for i, case in enumerate(cases):\n",
    "    print(\"Evaluating the models with data from the case #{}\".format(i+1))\n",
    "    for j, clf in enumerate(classifiers):\n",
    "        #train model with train data\n",
    "        clf.fit(X=case['x_train'], y=case['y_train'])\n",
    "        #predict test data\n",
    "        predictions = clf.predict(X=case['x_test'])\n",
    "        #calculate the accuracy\n",
    "        accuracy = accuracy_score(case['y_test'], predictions)\n",
    "\n",
    "        print(\"\\t Classifier #{} achieved {} accuracy on test data.\".format(j+1, accuracy))\n",
    "\n",
    "\n",
    "# Implement Cross Validation using Logistic Regression classifier\n",
    "# Using MinMax Normalized data given it performed better\n",
    "print(\"Running Cross-Validation using Logistic Regression classifier \\n\"\n",
    "    +\"and MinMax-Normalized data given it performed better...\")\n",
    "clf = LogisticRegression()\n",
    "# Use all data available (slice=1.0):\n",
    "xNorm, xMinMax, xNoNorm, y, xMean, xDev = siivoaData(df, slice=1.0)\n",
    "# 5 fold cross validation\n",
    "scores = cross_val_score(clf, xMinMax, y, verbose=1, cv=5)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
