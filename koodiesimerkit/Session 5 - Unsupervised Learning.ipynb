{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca reduced loan status data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use AirBNB data instead:\n",
    "    Identify different types of appartments for ex.\n",
    "    \n",
    "OR\n",
    "\n",
    "Stackexchange data - Technology Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "import warnings\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"credit_train.csv\")\n",
    "\n",
    "def siivoaData(data, slice=1.0):\n",
    "\n",
    "    # Mikä on muuttuja josta olemme kiinnostuneita?\n",
    "    # Haluamme tietysti ymmärtää muuttujaa lainan tilanne \"Loan staus\"\n",
    "    # Dikotominne muuttuja kuvaa sitä maksetaanko laina takaisin vai ei.\n",
    "\n",
    "    #Haluammeko poistaa jotain muuttujia?\n",
    "    poistettavatMuuttujat = ['Loan ID','Customer ID']\n",
    "    data = data.drop(poistettavatMuuttujat, axis=1)\n",
    "\n",
    "    #Annetaan keskiarvot puutuville tietopisteille\n",
    "    sarakkeet =['Current Loan Amount','Credit Score','Annual Income','Years of Credit History',\n",
    "            'Months since last delinquent','Number of Open Accounts','Number of Credit Problems',\n",
    "           'Current Credit Balance','Maximum Open Credit','Bankruptcies','Tax Liens']\n",
    "    muuttujanTäyttäjä = Imputer()\n",
    "    data[sarakkeet] = muuttujanTäyttäjä.fit_transform(data[sarakkeet])\n",
    "    data[sarakkeet] = data[sarakkeet].astype(int)\n",
    "\n",
    "    #Poistetaan vielä NaN rivit\n",
    "    data=data.dropna()\n",
    "\n",
    "    #Note:  Discarding half of the data for testing purposes!\n",
    "    index = int(len(data)*slice)\n",
    "    data = data.loc[:index]\n",
    "\n",
    "\n",
    "    #Valitaan muuttuja josta olemme kiinnostuneita ja koodataan se\n",
    "    y = data['Loan Status']\n",
    "    new_y = []\n",
    "    for i in y:\n",
    "        if i == 'Fully Paid':\n",
    "            new_y.append(1)\n",
    "        else:\n",
    "            new_y.append(0)\n",
    "    data = data.drop('Loan Status', axis=1)\n",
    "\n",
    "    # Koodataan kategoriset muuttujat\n",
    "    data = pd.get_dummies(data)\n",
    "    #print(data.head())\n",
    "\n",
    "    # Normalisoidaan data\n",
    "    # Palautamme myös dataMean ja dataDev arvot jos haluamme syöttää koneelle uusia havaintoja\n",
    "    dataMean = np.mean(data, axis=0)\n",
    "    dataDev = np.std(data, axis=0)\n",
    "    norm_x= (data - dataMean) / dataDev\n",
    "\n",
    "    x = data.values #muutetaan numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    normMinMax = pd.DataFrame(x_scaled)\n",
    "\n",
    "    return norm_x, normMinMax, data, new_y, dataMean, dataDev\n",
    "\n",
    "\n",
    "xNorm, xMinMax, xNoNorm, y, xMean, xDev = siivoaData(df, slice=0.01)\n",
    "\n",
    "print(xMinMax.head())\n",
    "\n",
    "pca = PCA(n_components=43)\n",
    "reducedX = pca.fit_transform(xMinMax)\n",
    "print(\"Explained variance of 43 components:\\n\",pca.explained_variance_ratio_)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reducedX = pca.fit_transform(xMinMax)\n",
    "\n",
    "colors = ['blue' if l==1 else 'red' for l in y]\n",
    "for dp, c in zip(reducedX, colors):\n",
    "    plt.scatter(dp[0], dp[1], color=c)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Performing predictions with reduced dimensionality\n",
    "xNorm, xMinMax, xNoNorm, y, xMean, xDev = siivoaData(df, slice=0.5)\n",
    "\n",
    "for n_comp in [3, 10, 20, 43]:\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    reducedX = pca.fit_transform(xMinMax)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reducedX, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    score = accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "    print('Accuracy with {} components: {}'.format(n_comp, score))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
