{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Crawlers and Scrapers</h1>\n",
    "\n",
    "The goal of this session is to build and run our own Amazon.com scraper using the **scrapy** python library. \n",
    "\n",
    "Our scraper will crawl through a specific product's customer review pages and get all of the available ratings and reviews. This will allow us to get complete review details that we canâ€™t get with the Amazon Product Advertising API.\n",
    "\n",
    "First we will install scrapy using pip command in terminal/cmd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use scrapy to automatically generate a skeleton of the code needed for our scraper. (On terminal/cmd type the following command without the exclamation mark):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy genspider amazon_scraper amazon.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new python-script, amazon_scraper.py file will be created. The final content of our scraper will be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import scrapy\n",
    "\n",
    "class AmazonScraperSpider(scrapy.Spider):\n",
    "    name = 'amazon_scraper'\n",
    "    allowed_domains = ['amazon.com']\n",
    "    # assing a product-review-page url below\n",
    "    start_urls = ['https://www.amazon.com/Apple-iPhone-Verizon-Unlocked-Renewed/product-reviews/B07HYDFX8G/ref=cm_cr_arp_d_viewopt_srt?ie=UTF8&reviewerType=all_reviews&sortBy=helpful&pageNumber=1']\n",
    "    \n",
    "    def parse(self, response):\n",
    "        review_texts = response.css('.a-size-base.review-text')\n",
    "        for i in range(len(review_texts)):\n",
    "            review_texts[i] = \"\".join(review_texts[i].css('::text').extract()).strip()\n",
    "\n",
    "        review_ratings = response.css('[data-hook=\"review-star-rating\"] > span::text').extract()\n",
    "\n",
    "        for i in range(len(review_texts)):\n",
    "            review = {\n",
    "                'text' : review_texts[i],\n",
    "                'rating': review_ratings[i]\n",
    "            }\n",
    "            yield review\n",
    "\n",
    "        next_page_url = response.css('.a-last > a::attr(href)').extract_first()\n",
    "        yield response.follow(next_page_url, self.parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can call the script from terminal/cmd as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy runspider amazon_scraper.py -o out.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
